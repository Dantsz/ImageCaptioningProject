{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4143834",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8549e254",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"git+https://github.com/salaniz/pycocoevalcap.git\"\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# I often use the line magics - Stackoverflow user\n",
    "import sys\n",
    "import os\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "repo_token = None\n",
    "if IN_COLAB:\n",
    "  from google.colab import userdata\n",
    "  repo_token = userdata.get('GITHUB_TOKEN')\n",
    "repo_url = None\n",
    "if repo_token is None: #use ssh, for local development\n",
    "    repo_url = f'git+ssh://git@github.com/Dantsz/aiimgdetect.git'\n",
    "else:\n",
    "    repo_url = f'git+https://Dantsz:{repo_token}@github.com/Dantsz/aiimgdetect.git'\n",
    "\n",
    "%pip install --upgrade {repo_url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4132e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "%pip install loguru\n",
    "from loguru import logger\n",
    "import sys\n",
    "import torch\n",
    "# allow all messages\n",
    "logger.remove()\n",
    "logger_id = logger.add(sys.stderr, level=\"TRACE\", colorize=True, format=\"<level>{level}</level>: {message} | {name}:{function}:{line} | {time:HH:mm:ss DD-MM-YYYY}\")\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "logger.info(\"Colab? : {}\", IN_COLAB)\n",
    "if IN_COLAB:\n",
    "  logger.info(\"Mounitng Google drive\")\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "logger.info(\"Python version: {}\", sys.version)\n",
    "logger.info(\"Torch version: {}\", torch.__version__)\n",
    "logger.info(\"Cuda available? : {}\", torch.cuda.is_available())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logger.info(\"Running on {}\", device)\n",
    "%env KAGGLEHUB_CACHE=datasets\n",
    "import kagglehub\n",
    "import os\n",
    "logger.info(\"Importing dataset to {}\", os.environ[\"KAGGLEHUB_CACHE\"])\n",
    "path = kagglehub.dataset_download(\"clkmuhammed/microsoft-coco-2017-common-objects-in-context\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "import sys\n",
    "logger.remove(logger_id)\n",
    "logger_id = logger.add(sys.stderr, level=\"WARNING\", colorize=True, format=\"<level>{level}</level>: {message} | {name}:{function}:{line} | {time:HH:mm:ss DD-MM-YYYY}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e953f111",
   "metadata": {},
   "source": [
    "# Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be023bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model, GPT2Config\n",
    "from adic_components.prototype2 import P2GPTBlock\n",
    "from adic_components.prototype3 import P3ECDEC, P3Decoder\n",
    "from adic_components.DyT import DyT\n",
    "from adic_components.CaptionsDataset import add_bos_eos\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "gpt2_model_pretrained = GPT2Model.from_pretrained('gpt2')\n",
    "# Get model config to know vocab size and hidden size\n",
    "config = GPT2Config.from_pretrained('gpt2')\n",
    "vocab_size = config.vocab_size\n",
    "hidden_size = config.n_embd\n",
    "gpt2 = P2GPTBlock(config)\n",
    "gpt2.load_state_dict(gpt2_model_pretrained.state_dict(), strict=False)\n",
    "decoder = P3Decoder(config)\n",
    "decoder.gpt2 = gpt2\n",
    "encodeco = P3ECDEC(3, 224, 224, hidden_size, decoder)\n",
    "COLAB_WEIGHTS_FILE = '/content/drive/MyDrive/prototype3_release12.pth'\n",
    "LOCAL_WIEIGHTS_FILE = 'prototype3_release12.pth'\n",
    "model = encodeco.to(device)\n",
    "#freze the decoder\n",
    "# how about no for once\n",
    "for name, param in model.decoder.gpt2.named_parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c92b958",
   "metadata": {},
   "outputs": [],
   "source": [
    "READ_WEIGHTS_FROM_FILE = True\n",
    "if READ_WEIGHTS_FROM_FILE:\n",
    "  if IN_COLAB:\n",
    "   try:\n",
    "      logger.info(\"Loading model from file\")\n",
    "      model.load_state_dict(torch.load(COLAB_WEIGHTS_FILE, map_location=torch.device(device)))\n",
    "   except:\n",
    "      logger.error(\"Loading model from file failed, going with default weights\")\n",
    "  else:\n",
    "   logger.info(\"Loading model from file\")\n",
    "   try:\n",
    "      model.load_state_dict(torch.load(LOCAL_WIEIGHTS_FILE, map_location=torch.device(device)))\n",
    "   except:\n",
    "      logger.error(\"Loading model from file failed, going with default weights\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1721f4f6",
   "metadata": {},
   "source": [
    "# Setup dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6543914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocoevalcap.eval import COCOEvalCap\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from adic_components.CaptionsDataset import CaptionDatasetPyCOCO, augmentation_train_transform, default_tokenizer, augmentation_test_transform\n",
    "import tqdm\n",
    "import os\n",
    "import json\n",
    "val_path = os.path.join(path, 'annotations_trainval2017/captions_val2017.json')\n",
    "print(\"Path to validation split: \", val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862459e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CaptionDatasetPyCOCO(\n",
    "    images_dir=os.path.join(path, 'val2017'),\n",
    "    json_path=val_path,\n",
    "    transform=augmentation_test_transform,\n",
    "    tokenizer=default_tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e300ed",
   "metadata": {},
   "source": [
    "# Generate predictions.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02250480",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqdm.tqdm(range(len(dataset))):\n",
    "        img, c = dataset[i]\n",
    "        id = dataset.get_image_id_by_index(i)\n",
    "        img_pixel_values = img.to(device)\n",
    "        decoder_output = model.generate(img_pixel_values.unsqueeze(0))\n",
    "        generated = default_tokenizer.batch_decode(decoder_output.cpu().tolist(), skip_special_tokens=True)\n",
    "        predictions.append({\n",
    "            'image_id': id,\n",
    "            'caption': generated[0]\n",
    "        })\n",
    "pred_file = 'predictions.json'\n",
    "with open(pred_file, 'w') as f:\n",
    "    json.dump(predictions, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da661289",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d431baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco = COCO(val_path)  # Your ground-truth JSON file\n",
    "cocoRes = coco.loadRes(pred_file)\n",
    "\n",
    "cocoEval = COCOEvalCap(coco, cocoRes)\n",
    "cocoEval.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
